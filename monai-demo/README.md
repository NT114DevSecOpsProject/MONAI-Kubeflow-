# MONAI Spleen Segmentation - Domain Shift Analysis

Complete testing & analysis of MONAI pretrained spleen segmentation model on two datasets.

**Key Finding**: 47.7% performance drop due to domain shift (Dice 0.88 â†’ 0.46)

---

## ğŸš€ Quick Start

```bash
# Read overview
cat docs/00_READ_ME.md

# Test on Task09_Spleen (training domain)
cd task09_spleen/scripts
python 01_test_task09.py

# Test on TotalSegmentator (test domain)
cd ../../totalsegmentator/scripts
python 02_test_totalseg.py

# Create comparison chart
python 01_compare_results.py

# View results
cat ../outputs/results.csv
```

---

## ğŸ“Š Results Summary

| Dataset | Dice | Status | Cases |
|---------|------|--------|-------|
| **Task09_Spleen** | 0.8797 | âœ… Excellent | 90% excellent |
| **TotalSegmentator** | 0.4597 | âŒ Moderate | 30% excellent |
| **Difference** | **-47.7%** | âš ï¸ Domain shift | -60% |

---

## ğŸ“ Folder Structure

```
monai-demo/
â”œâ”€â”€ README.md                           â† You are here
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ 00_READ_ME.md                  â† Start here
â”‚   â”œâ”€â”€ RESULTS.md                     â† Key findings
â”‚   â””â”€â”€ USAGE.md                       â† How to run
â”œâ”€â”€ task09_spleen/                     â† Task09_Spleen section
â”‚   â”œâ”€â”€ README.md                      â† Task09 guide
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â””â”€â”€ 01_test_task09.py
â”‚   â””â”€â”€ outputs/
â”œâ”€â”€ totalsegmentator/                  â† TotalSegmentator section
â”‚   â”œâ”€â”€ README.md                      â† TotalSeg guide
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ 01_compare_results.py
â”‚   â”‚   â”œâ”€â”€ 02_reorganize_data.py
â”‚   â”‚   â”œâ”€â”€ 02_test_totalseg.py
â”‚   â”‚   â””â”€â”€ 02_visualize_cases.py
â”‚   â””â”€â”€ outputs/
â”œâ”€â”€ test_data/                         â† Datasets
â”‚   â”œâ”€â”€ Task09_Spleen/
â”‚   â””â”€â”€ TotalSegmentator_small/
â””â”€â”€ [Images & other files]
```

---

## ğŸ“š Documentation

| File | Purpose |
|------|---------|
| [docs/00_READ_ME.md](docs/00_READ_ME.md) | Overview & quick start |
| [docs/RESULTS.md](docs/RESULTS.md) | Detailed findings & analysis |
| [docs/USAGE.md](docs/USAGE.md) | How to run scripts |

---

## âš¡ Quick Commands

```bash
# Test TotalSegmentator
cd scripts/evaluation && python 02_test_totalseg.py

# Test Task09_Spleen
cd scripts/evaluation && python 01_test_task09.py

# Create comparison chart
cd scripts/visualization && python 01_compare_results.py

# View results
cat outputs/totalsegmentator_test/results.csv
```

---

## ğŸ¯ What This Shows

This project demonstrates **domain shift** in machine learning:

1. **Model trains on Task09_Spleen**: Achieves Dice 0.88 âœ…
2. **Model tested on TotalSegmentator**: Achieves Dice 0.46 âŒ
3. **Conclusion**: 47.7% performance drop due to different data distribution

**Key insight**: Pre-trained models don't work on different domains without fine-tuning!

---

## ğŸ”‘ Key Findings

âœ… **Task09_Spleen (Training Data)**
- Dice: 0.8797 Â± 0.1690
- 90% excellent cases
- 19.2% variability (consistent)

âŒ **TotalSegmentator (Test Data)**
- Dice: 0.4597 Â± 0.3356
- 30% excellent cases
- 73.0% variability (inconsistent)

âš ï¸ **Domain Shift Impact**
- Dice drop: -47.7%
- Variability increase: +3.8x
- Excellent cases decrease: -60%

---

## ğŸ“Š Main Visualization

**File**: `outputs/comparison_task09_vs_totalseg.png`

6-panel comparison showing:
1. Dice score (0.88 vs 0.46)
2. IoU score
3. Variability (19% vs 73%)
4. Distribution histogram
5. Performance categories
6. Statistics table

---

## ğŸ“– Script Organization

### `scripts/evaluation/` - Test Models
- `01_test_task09.py` - Test on Task09_Spleen (training data)
- `02_test_totalseg.py` - Test on TotalSegmentator

### `scripts/visualization/` - Create Charts
- `01_compare_results.py` - Create comparison chart
- `02_visualize_cases.py` - 3-panel case visualizations

### `scripts/data_prep/` - Prepare Data
- `01_download_data.py` - Download TotalSegmentator
- `02_reorganize_data.py` - Reorganize data structure

### `scripts/utilities/` - Utilities
- `01_demo.py` - Demo script

---

## ğŸ“ˆ Output Files

```
outputs/
â”œâ”€â”€ comparison_task09_vs_totalseg.png    â† Main chart
â”œâ”€â”€ task09_spleen_test/
â”‚   â”œâ”€â”€ results.csv
â”‚   â””â”€â”€ summary.json
â”œâ”€â”€ totalsegmentator_test/
â”‚   â”œâ”€â”€ results.csv
â”‚   â”œâ”€â”€ metrics_report.png
â”‚   â””â”€â”€ summary_statistics.png
â””â”€â”€ totalsegmentator_visualizations_fixed/
    â”œâ”€â”€ s0011_segmentation.png (excellent)
    â”œâ”€â”€ s0310_segmentation.png (poor)
    â””â”€â”€ ... (12 more cases)
```

---

## ğŸ“ Why This Matters

1. **Pre-trained models have limitations**
   - Work well on training domain
   - Fail on different domains

2. **Domain shift is critical challenge**
   - Different hospitals, scanners, protocols
   - Same organ, different image characteristics

3. **Always validate on target domain**
   - Before deployment
   - Before making decisions
   - Before claiming success

---

## ğŸ’¡ Recommendations

âŒ **Don't**: Use model directly on TotalSegmentator

âœ… **Do**:
1. Fine-tune on TotalSegmentator (expected Dice 0.75-0.85)
2. Or retrain from scratch (expected Dice 0.85-0.92)
3. Always validate on your target domain

---

## ğŸ“ Need Help?

1. **Getting started?**
   â†’ Read [docs/00_READ_ME.md](docs/00_READ_ME.md)

2. **Want detailed results?**
   â†’ See [docs/RESULTS.md](docs/RESULTS.md)

3. **How to run tests?**
   â†’ Check [docs/USAGE.md](docs/USAGE.md)

4. **Find a script?**
   â†’ Browse `scripts/` folder by purpose

---

## ğŸš€ Next Steps

1. Read [docs/00_READ_ME.md](docs/00_READ_ME.md)
2. Review [docs/RESULTS.md](docs/RESULTS.md)
3. Run a test: `cd scripts/evaluation && python test_totalsegmentator_spleen.py`
4. View chart: `outputs/comparison_task09_vs_totalseg.png`

---

**For complete details, see documentation in `docs/` folder**

Generated: 2025-10-27 | Updated: 2025-10-27
