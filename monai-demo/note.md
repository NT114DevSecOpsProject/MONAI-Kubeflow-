# MONAI Pretrained Models - HÆ°á»›ng Dáº«n Chi Tiáº¿t

## Má»¥c Lá»¥c
1. [MONAI cÃ³ bao nhiÃªu model train sáºµn?](#1-monai-cÃ³-bao-nhiÃªu-model-train-sáºµn)
2. [CÃ³ thá»ƒ thÃªm dá»¯ liá»‡u vÃ o Ä‘Æ°á»£c khÃ´ng?](#2-cÃ³-thá»ƒ-thÃªm-dá»¯-liá»‡u-vÃ o-Ä‘Æ°á»£c-khÃ´ng)
3. [Model lÃ¡ lÃ¡ch Ä‘Æ°á»£c train nhÆ° tháº¿ nÃ o?](#3-model-lÃ¡-lÃ¡ch-Ä‘Æ°á»£c-train-nhÆ°-tháº¿-nÃ o)
4. [So sÃ¡nh: MONAI vs Hugging Face](#4-so-sÃ¡nh-monai-vs-hugging-face)
5. [Xem thÃ´ng tin á»Ÿ Ä‘Ã¢u?](#5-xem-thÃ´ng-tin-á»Ÿ-Ä‘Ã¢u)

---

## 1. MONAI cÃ³ bao nhiÃªu model train sáºµn?

### âœ… Tá»•ng cá»™ng: 35 pretrained models trong MONAI Model Zoo

### ğŸ«€ Organ Segmentation (PhÃ¢n Ä‘oáº¡n cÆ¡ quan)
- `spleen_ct_segmentation` â† Äang dÃ¹ng
- `pancreas_ct_dints_segmentation` - PhÃ¢n Ä‘oáº¡n tá»¥y
- `prostate_mri_anatomy` - PhÃ¢n Ä‘oáº¡n tuyáº¿n tiá»n liá»‡t
- `wholeBody_ct_segmentation` - PhÃ¢n Ä‘oáº¡n toÃ n thÃ¢n (104 cÆ¡ quan!)
- `renalStructures_UNEST_segmentation` - PhÃ¢n Ä‘oáº¡n tháº­n
- `multi_organ_segmentation` - Äa cÆ¡ quan
- `pediatric_abdominal_ct_segmentation` - Bá»¥ng tráº» em

### ğŸ§  Brain Imaging (HÃ¬nh áº£nh nÃ£o)
- `brats_mri_segmentation` - Khá»‘i u nÃ£o (BraTS dataset)
- `wholeBrainSeg_Large_UNEST_segmentation` - PhÃ¢n Ä‘oáº¡n nÃ£o

### ğŸ« Lung/Chest (Phá»•i/Ngá»±c)
- `lung_nodule_ct_detection` - PhÃ¡t hiá»‡n ná»‘t phá»•i
- `cxr_image_synthesis_latent_diffusion_model` - Táº¡o áº£nh X-quang ngá»±c

### ğŸ”¬ Pathology (MÃ´ bá»‡nh há»c)
- `pathology_tumor_detection` - PhÃ¡t hiá»‡n khá»‘i u
- `pathology_nuclei_segmentation_classification` - PhÃ¢n Ä‘oáº¡n nhÃ¢n táº¿ bÃ o
- `pathology_nuclick_annotation` - CÃ´ng cá»¥ annotation

### ğŸ‘ï¸ Retina/Eye (VÃµng máº¡c)
- `retinalOCT_RPD_segmentation` - PhÃ¢n Ä‘oáº¡n vÃµng máº¡c OCT

### ğŸ¥ Endoscopy (Ná»™i soi)
- `endoscopic_tool_segmentation` - PhÃ¢n Ä‘oáº¡n dá»¥ng cá»¥ ná»™i soi
- `endoscopic_inbody_classification` - PhÃ¢n loáº¡i trong/ngoÃ i cÆ¡ thá»ƒ

### ğŸ¤– AI Generation (Táº¡o áº£nh AI)
- `maisi_ct_generative` - Táº¡o CT scan giáº£
- `brats_mri_generative_diffusion` - Táº¡o MRI nÃ£o
- `brain_image_synthesis_latent_diffusion_model` - Latent diffusion cho nÃ£o

### ğŸ† Advanced Models
- `vista3d` - Model foundation 3D (universal segmentation)
- `vista2d` - Model foundation 2D
- `swin_unetr_btcv_segmentation` - BTCV dataset (Ä‘a cÆ¡ quan)

---

## 2. CÃ³ thá»ƒ thÃªm dá»¯ liá»‡u vÃ o Ä‘Æ°á»£c khÃ´ng?

### âœ… CÃ“ - CÃ³ 3 cÃ¡ch chÃ­nh:

### ğŸ”¹ CÃ¡ch 1: Fine-tuning (Äá» xuáº¥t)

**Ká»‹ch báº£n:** Bá»‡nh viá»‡n cÃ³ 50 CT scan riÃªng cá»§a mÃ¬nh

**CÃ¡c bÆ°á»›c:**
1. Load pretrained model
2. Freeze cÃ¡c layer Ä‘áº§u (feature extraction)
3. Train láº¡i cÃ¡c layer cuá»‘i trÃªn 50 CT scan má»›i
4. ÄÃ¡nh giÃ¡ trÃªn validation set

**Káº¿t quáº£:**
- Thá»i gian: 2-4 giá» training
- Dice tÄƒng tá»« 0.97 â†’ 0.98-0.99
- Tiáº¿t kiá»‡m thá»i gian (khÃ´ng train tá»« Ä‘áº§u)
- Cáº§n Ã­t data hÆ¡n (50 máº«u thay vÃ¬ 500+)
- Model há»c Ä‘Æ°á»£c Ä‘áº·c Ä‘iá»ƒm riÃªng cá»§a bá»‡nh viá»‡n

### ğŸ”¹ CÃ¡ch 2: Transfer Learning

**Ká»‹ch báº£n:** Muá»‘n phÃ¢n Ä‘oáº¡n cÆ¡ quan khÃ¡c (vÃ­ dá»¥: gan)

**CÃ¡c bÆ°á»›c:**
1. Load spleen_ct_segmentation model
2. Thay Ä‘á»•i output layer (2 classes â†’ 3 classes náº¿u cáº§n)
3. Train trÃªn dataset gan
4. Model há»c nhanh vÃ¬ Ä‘Ã£ biáº¿t cáº¥u trÃºc CT scan

**Káº¿t quáº£:**
- Thá»i gian: 5-10 giá» training
- Nhanh hÆ¡n train tá»« Ä‘áº§u 5-10 láº§n

### ğŸ”¹ CÃ¡ch 3: Incremental Learning

**Ká»‹ch báº£n:** CÃ³ data má»›i liÃªn tá»¥c Ä‘áº¿n (bá»‡nh viá»‡n má»—i thÃ¡ng thÃªm 10 ca)

**CÃ¡c bÆ°á»›c:**
1. Start vá»›i pretrained model
2. Má»—i thÃ¡ng train thÃªm trÃªn 10 ca má»›i
3. Model cáº£i thiá»‡n dáº§n theo thá»i gian

**Lá»£i Ã­ch:**
- Model ngÃ y cÃ ng tá»‘t hÆ¡n vá»›i data riÃªng
- KhÃ´ng cáº§n retrain toÃ n bá»™

---

## 3. Model lÃ¡ lÃ¡ch Ä‘Æ°á»£c train nhÆ° tháº¿ nÃ o?

### ğŸ“Š Dataset ChÃ­nh Thá»©c

**TÃªn:** Medical Segmentation Decathlon - **Task09_Spleen**

**Nguá»“n:**
- ğŸŒ Website: http://medicaldecathlon.com/
- ğŸ“„ Paper: Nature Communications (2022)
- ğŸ¥ Bá»‡nh viá»‡n: Memorial Sloan Kettering Cancer Center (New York, USA)

**KÃ­ch thÆ°á»›c:**
```
Tá»•ng sá»‘: 61 CT scans
â”œâ”€ Training: 41 CT scans (vá»›i ground truth)
â””â”€ Testing:  20 CT scans (public test set)
```

**Äáº·c Ä‘iá»ƒm:**
- Modality: CT scan (Computed Tomography)
- Target: Spleen (lÃ¡ lÃ¡ch)
- Format: NIfTI (.nii.gz)
- Challenge: Large-ranging foreground size (lÃ¡ lÃ¡ch cÃ³ kÃ­ch thÆ°á»›c thay Ä‘á»•i lá»›n)

### ğŸ—ï¸ Architecture

**Model:** UNet 3D
- Input: 1 channel (CT scan)
- Output: 2 channels (background, spleen)
- Layers: [16, 32, 64, 128, 256] channels
- Parameters: 4.8 triá»‡u
- Patch size: 96Ã—96Ã—96 voxels

### âš™ï¸ Training Configuration

**Hardware:**
- GPU: Ãt nháº¥t 12GB VRAM
- Actual GPU used: NVIDIA V100/A100

**Hyperparameters:**
- Epochs: 800 (actual best: ~1260 epochs)
- Optimizer: Novograd
- Learning rate: 0.002
- Loss function: DiceCELoss (50% Dice + 50% CrossEntropy)
- AMP (Automatic Mixed Precision): True
- Dataset Manager: CacheDataset

**Data Split:**
- Training: 32 CT scans
- Validation: 9 CT scans

### ğŸ”„ Preprocessing (Training time)

1. `LoadImaged` - Load CT scan vÃ  ground truth
2. `EnsureChannelFirstd` - Äáº£m báº£o channel Ä‘áº§u tiÃªn
3. `Orientationd` - Chuáº©n hÃ³a hÆ°á»›ng (RAS)
4. `Spacingd` - Resample spacing
5. `ScaleIntensityRanged` - Normalize intensity
6. `CropForegroundd` - Crop foreground
7. `RandCropByPosNegLabeld` - Random crop patches 96Ã—96Ã—96
8. `RandFlipd` - Random flip augmentation
9. `RandRotate90d` - Random rotation
10. `EnsureTyped` - Convert to tensor

### ğŸ“ˆ Performance Äáº¡t ÄÆ°á»£c

**Káº¿t quáº£ chÃ­nh thá»©c:**
- Mean Dice Score: **0.961 (96.1%)**
- TrÃªn validation set (9 CT scans)
- Äáº¡t Runner-up Award táº¡i Medical Segmentation Decathlon 2018

**Training graphs:**
- Training loss: Giáº£m dáº§n qua 1260 epochs
- Validation Dice: Äáº¡t 0.96-0.97

### ğŸ“Š Dataset Statistics

**Training data (41 CT scans):**
- Patient ages: 18-90 years old
- Both genders
- Different spleen conditions:
  * Normal spleen
  * Splenomegaly (enlarged)
  * Post-trauma
  * Cancer patients

**Image characteristics:**
- Voxel spacing: Variable (0.5-1.0 mm)
- Image size: Variable (typically 512Ã—512Ã—[100-300] slices)
- Hounsfield Units: -1024 to 3071 HU
- File format: NIfTI (.nii.gz)

**Ground truth:**
- Manual annotation by expert radiologists
- Each voxel labeled: 0 (background) or 1 (spleen)
- Inter-rater agreement: >95% Dice

---

## 4. So sÃ¡nh: MONAI vs Hugging Face

### ğŸ“Š Báº£ng So SÃ¡nh

| TiÃªu chÃ­ | MONAI Model Zoo | Hugging Face |
|----------|-----------------|--------------|
| **Sá»‘ lÆ°á»£ng medical models** | 35 models chuyÃªn sÃ¢u | ~10-15 models general |
| **ChuyÃªn mÃ´n hÃ³a** | 100% medical imaging | Äa lÄ©nh vá»±c (NLP, CV, Audio) |
| **Data format** | NIfTI, DICOM (medical) | PNG, JPG, MP4 (general) |
| **Preprocessing** | HU normalization, spacing | RGB normalization |
| **Model architecture** | UNet 3D, UNETR (medical) | ViT, SAM (general vision) |

### ğŸ¤ Medical Models trÃªn Hugging Face

1. **facebook/sam-vit-huge** (Segment Anything Model)
   - General purpose segmentation
   - CÃ³ thá»ƒ dÃ¹ng cho medical (nhÆ°ng kÃ©m hÆ¡n MONAI)
   - KhÃ´ng hiá»ƒu HU values, spacing

2. **microsoft/swin-tiny-patch4-window7-224**
   - Vision Transformer
   - CÃ³ thá»ƒ fine-tune cho medical classification
   - NhÆ°ng thiáº¿u medical-specific features

3. **google/vit-base-patch16-224**
   - ViT for image classification
   - DÃ¹ng cho phÃ¢n loáº¡i bá»‡nh (cÃ³/khÃ´ng cÃ³ khá»‘i u)

### âœ… CÃ³ láº¥y model tá»« Hugging Face vÃ o Ä‘Æ°á»£c khÃ´ng?

**CÃ“ - NhÆ°ng pháº£i lÃ m thÃªm nhiá»u viá»‡c:**

**VÃ­ dá»¥: DÃ¹ng SAM cho medical:**
1. Download SAM tá»« Hugging Face
2. Convert CT scan sang format SAM hiá»ƒu (PNG)
3. Máº¥t medical metadata (spacing, orientation)
4. Inference vá»›i SAM
5. Post-process káº¿t quáº£

**Káº¿t quáº£:**
- Dice ~0.70-0.80 (kÃ©m hÆ¡n MONAI 0.97)
- LÃ½ do: SAM khÃ´ng hiá»ƒu medical imaging specifics

### ğŸ“¤ Upload MONAI model lÃªn Hugging Face?

**CÃ“ THá»‚ - Äá»ƒ share vá»›i cá»™ng Ä‘á»“ng:**

1. Save MONAI model weights
2. Táº¡o Hugging Face repository
3. Upload model + config + preprocessing code
4. Táº¡o model card (README)
5. NgÆ°á»i khÃ¡c download vÃ  dÃ¹ng

**URL:** huggingface.co/your-name/monai-spleen-ct

---

## 5. Xem thÃ´ng tin á»Ÿ Ä‘Ã¢u?

### ğŸ’» Local Files (TrÃªn mÃ¡y)

**ThÆ° má»¥c model:**
```
E:\monai-kubeflow-demo\models\spleen_ct_segmentation\
â”œâ”€ docs/
â”‚  â””â”€ README.md          â† Chi tiáº¿t Ä‘áº§y Ä‘á»§ vá» model
â”œâ”€ configs/
â”‚  â”œâ”€ metadata.json      â† ThÃ´ng tin metadata
â”‚  â”œâ”€ train.json         â† Config training
â”‚  â”œâ”€ inference.json     â† Config inference
â”‚  â””â”€ evaluate.json      â† Config evaluation
â””â”€ models/
   â””â”€ model.pt           â† Model weights (220MB)
```

### ğŸŒ Online Resources

**a) MONAI Model Zoo:**
- URL: https://monai.io/model-zoo.html
- TÃ¬m "Spleen CT Segmentation"
- CÃ³ link download, documentation, demo

**b) GitHub Repository:**
- URL: https://github.com/Project-MONAI/model-zoo/tree/dev/models/spleen_ct_segmentation
- Source code Ä‘áº§y Ä‘á»§
- Config files
- Training scripts
- Version history

**c) Medical Segmentation Decathlon:**
- URL: http://medicaldecathlon.com/
- Download dataset gá»‘c (Task09_Spleen.tar)
- Xem leaderboard
- Äá»c paper: https://doi.org/10.1038/s41467-022-30695-9

**d) NVIDIA Clara:**
- URL: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/monaitoolkit/models/monai_spleen_ct_segmentation
- NVIDIA hosting
- Pre-trained weights
- Deployment guides

### ğŸ“š Papers vÃ  References

**Paper 1: Training Method**
- Title: "3D Semi-Supervised Learning with Uncertainty-Aware Multi-View Co-Training"
- Authors: Xia, Yingda, et al.
- Year: 2018
- Link: https://arxiv.org/abs/1811.12506
- Ná»™i dung: PhÆ°Æ¡ng phÃ¡p training Ä‘Æ°á»£c dÃ¹ng cho model nÃ y

**Paper 2: Architecture**
- Title: "Left-Ventricle Quantification Using Residual U-Net"
- Authors: Kerfoot E., et al.
- Year: 2019
- Link: https://doi.org/10.1007/978-3-030-12029-0_40
- Ná»™i dung: UNet architecture vá»›i residual connections

**Paper 3: Dataset**
- Title: "A large annotated medical image dataset for the development and evaluation of segmentation algorithms"
- Authors: Medical Segmentation Decathlon Consortium
- Year: 2022
- Journal: Nature Communications
- Link: https://doi.org/10.1038/s41467-022-30695-9
- Ná»™i dung: Giá»›i thiá»‡u toÃ n bá»™ Medical Decathlon dataset

---

## ğŸ“‹ TÃ³m Táº¯t ThÃ´ng Tin Model

| ThÃ´ng tin | GiÃ¡ trá»‹ |
|-----------|--------|
| **Dataset** | Medical Segmentation Decathlon Task09_Spleen |
| **Nguá»“n** | Memorial Sloan Kettering Cancer Center (USA) |
| **KÃ­ch thÆ°á»›c** | 61 CT scans (41 train + 20 test) |
| **Training data** | 32 training + 9 validation |
| **Model** | UNet 3D (4.8M parameters) |
| **Training time** | 1260 epochs (~30 giá» trÃªn V100) |
| **Dice Score** | 0.961 (96.1%) |
| **Award** | Runner-up - Medical Decathlon 2018 |
| **Xem thÃ´ng tin** | models/spleen_ct_segmentation/docs/README.md |
| **Download dataset** | http://medicaldecathlon.com/ |

---

## ğŸ¯ Khuyáº¿n Nghá»‹ Cho á»¨ng Dá»¥ng Bá»‡nh Viá»‡n

### âœ… NÃŠN DÃ™NG:
- MONAI Model Zoo - 35 models chuyÃªn medical imaging
- Pretrained sáºµn, chá»‰ cáº§n download
- Fine-tune Ä‘Æ°á»£c vá»›i data riÃªng
- Há»— trá»£ DICOM, NIfTI, medical preprocessing

### ğŸ¤ Káº¾T Há»¢P:
- MONAI (backend - AI model)
- Hugging Face Gradio (frontend - web interface)
- Hugging Face Spaces (hosting - deploy miá»…n phÃ­)

### âŒ KHÃ”NG NÃŠN:
- DÃ¹ng Hugging Face general models (SAM, ViT) cho medical
- LÃ½ do: KÃ©m chÃ­nh xÃ¡c, máº¥t medical metadata

### ğŸ”„ Workflow Äá» Xuáº¥t

```
[BÆ°á»›c 1] Download MONAI pretrained model
         â†“
[BÆ°á»›c 2] Test trÃªn data thá»±c táº¿ bá»‡nh viá»‡n
         â†“
[BÆ°á»›c 3] Náº¿u Dice > 0.90 â†’ DÃ¹ng luÃ´n
         Náº¿u Dice < 0.90 â†’ Fine-tune vá»›i data riÃªng
         â†“
[BÆ°á»›c 4] Deploy vá»›i Gradio web interface
         â†“
[BÆ°á»›c 5] (Optional) Upload lÃªn Hugging Face Spaces
         Ä‘á»ƒ bÃ¡c sÄ© dÃ¹ng qua web browser
```

**Káº¿t quáº£ cuá»‘i cÃ¹ng:**
- Model chÃ­nh xÃ¡c cao (Dice > 0.95)
- Web interface thÃ¢n thiá»‡n
- BÃ¡c sÄ© upload CT scan â†’ Nháº­n káº¿t quáº£ phÃ¢n Ä‘oáº¡n
- Tiáº¿t kiá»‡m 95% thá»i gian so vá»›i váº½ tay

---

**Last updated:** October 26, 2025
