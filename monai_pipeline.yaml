# PIPELINE DEFINITION
# Name: monai-medical-image-classification
# Description: Train and evaluate medical image classification model
# Inputs:
#    batch_size: int [Default: 32.0]
#    epochs: int [Default: 3.0]
components:
  comp-train-and-evaluate-model:
    executorLabel: exec-train-and-evaluate-model
    inputDefinitions:
      parameters:
        batch_size:
          parameterType: NUMBER_INTEGER
        epochs:
          parameterType: NUMBER_INTEGER
    outputDefinitions:
      artifacts:
        metrics_output:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
deploymentSpec:
  executors:
    exec-train-and-evaluate-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train_and_evaluate_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.14.6'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train_and_evaluate_model(\n    epochs: int,\n    batch_size:\
          \ int,\n    metrics_output: Output[Metrics]\n):\n    \"\"\"Train and evaluate\
          \ MONAI model with configurable parameters\n\n    This component has 2 phases:\n\
          \    Phase 1: Training - Train model and save best checkpoint\n    Phase\
          \ 2: Evaluation - Evaluate trained model on validation set\n    \"\"\"\n\
          \    import os\n    import torch\n    import glob\n    from monai.data import\
          \ Dataset\n    from monai.transforms import (\n        Compose, LoadImaged,\
          \ EnsureChannelFirstd,\n        ScaleIntensityd, RandRotate90d, RandFlipd,\
          \ ToTensord\n    )\n    from monai.networks.nets import DenseNet121\n  \
          \  from torch.utils.data import DataLoader\n\n    print(f\"\\n{'='*60}\"\
          )\n    print(f\"MONAI Pipeline - 2 Phase Execution\")\n    print(f\"{'='*60}\"\
          )\n    print(f\"Parameters: epochs={epochs}, batch_size={batch_size}\")\n\
          \    print(f\"{'='*60}\\n\")\n\n    # =====================================================\n\
          \    # PHASE 1: TRAINING\n    # =====================================================\n\
          \    print(f\"\\n{'#'*60}\")\n    print(f\"# PHASE 1: MODEL TRAINING\")\n\
          \    print(f\"{'#'*60}\\n\")\n\n    # Setup\n    device = torch.device(\"\
          cuda\" if torch.cuda.is_available() else \"cpu\")\n    data_dir = \"/app/data/MedNIST\"\
          \n\n    # Get class names\n    class_names = sorted([x for x in os.listdir(data_dir)\n\
          \                         if os.path.isdir(os.path.join(data_dir, x))])\n\
          \n    # Prepare data\n    train_data = []\n    val_data = []\n\n    for\
          \ i, class_name in enumerate(class_names):\n        class_dir = os.path.join(data_dir,\
          \ class_name)\n        class_images = glob.glob(os.path.join(class_dir,\
          \ \"*.jpeg\"))[:100]\n\n        split_idx = int(0.8 * len(class_images))\n\
          \n        for img in class_images[:split_idx]:\n            train_data.append({\"\
          image\": img, \"label\": i})\n        for img in class_images[split_idx:]:\n\
          \            val_data.append({\"image\": img, \"label\": i})\n\n    print(f\"\
          Training samples: {len(train_data)}\")\n    print(f\"Validation samples:\
          \ {len(val_data)}\\n\")\n\n    # Transforms\n    train_transforms = Compose([\n\
          \        LoadImaged(keys=[\"image\"]),\n        EnsureChannelFirstd(keys=[\"\
          image\"]),\n        ScaleIntensityd(keys=[\"image\"]),\n        RandRotate90d(keys=[\"\
          image\"], prob=0.5, spatial_axes=(0, 1)),\n        RandFlipd(keys=[\"image\"\
          ], prob=0.5),\n        ToTensord(keys=[\"image\"])\n    ])\n\n    val_transforms\
          \ = Compose([\n        LoadImaged(keys=[\"image\"]),\n        EnsureChannelFirstd(keys=[\"\
          image\"]),\n        ScaleIntensityd(keys=[\"image\"]),\n        ToTensord(keys=[\"\
          image\"])\n    ])\n\n    # Datasets and loaders\n    train_ds = Dataset(data=train_data,\
          \ transform=train_transforms)\n    val_ds = Dataset(data=val_data, transform=val_transforms)\n\
          \n    # Optimize DataLoader with parallel workers and pin memory\n    num_workers\
          \ = min(4, os.cpu_count() or 1)\n    train_loader = DataLoader(\n      \
          \  train_ds,\n        batch_size=batch_size,\n        shuffle=True,\n  \
          \      num_workers=num_workers,\n        pin_memory=True if torch.cuda.is_available()\
          \ else False,\n        persistent_workers=True if num_workers > 0 else False\n\
          \    )\n    val_loader = DataLoader(\n        val_ds,\n        batch_size=batch_size,\n\
          \        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=True\
          \ if torch.cuda.is_available() else False,\n        persistent_workers=True\
          \ if num_workers > 0 else False\n    )\n\n    # Model\n    model = DenseNet121(\n\
          \        spatial_dims=2,\n        in_channels=1,\n        out_channels=len(class_names)\n\
          \    ).to(device)\n\n    loss_function = torch.nn.CrossEntropyLoss()\n \
          \   optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\n    # Add\
          \ learning rate scheduler for better convergence\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n\
          \        optimizer, mode='max', factor=0.5, patience=2, verbose=True\n \
          \   )\n\n    # Mixed precision training for faster computation\n    scaler\
          \ = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n\
          \n    # Training\n    print(\"Training started...\\n\")\n    best_val_acc\
          \ = 0\n\n    for epoch in range(epochs):\n        model.train()\n      \
          \  epoch_loss = 0\n\n        for batch_data in train_loader:\n         \
          \   inputs = batch_data[\"image\"].to(device)\n            labels = batch_data[\"\
          label\"].to(device)\n\n            optimizer.zero_grad()\n\n           \
          \ # Use mixed precision if available\n            if scaler is not None:\n\
          \                with torch.cuda.amp.autocast():\n                    outputs\
          \ = model(inputs)\n                    loss = loss_function(outputs, labels)\n\
          \                scaler.scale(loss).backward()\n                scaler.step(optimizer)\n\
          \                scaler.update()\n            else:\n                outputs\
          \ = model(inputs)\n                loss = loss_function(outputs, labels)\n\
          \                loss.backward()\n                optimizer.step()\n\n \
          \           epoch_loss += loss.item()\n\n        avg_loss = epoch_loss /\
          \ len(train_loader)\n\n        # Validation\n        model.eval()\n    \
          \    val_correct = 0\n        val_total = 0\n\n        with torch.no_grad():\n\
          \            for val_batch in val_loader:\n                val_inputs =\
          \ val_batch[\"image\"].to(device)\n                val_labels = val_batch[\"\
          label\"].to(device)\n                val_outputs = model(val_inputs)\n \
          \               _, predicted = torch.max(val_outputs, 1)\n             \
          \   val_total += val_labels.size(0)\n                val_correct += (predicted\
          \ == val_labels).sum().item()\n\n        val_acc = 100 * val_correct / val_total\n\
          \n        # Update learning rate based on validation accuracy\n        scheduler.step(val_acc)\n\
          \n        current_lr = optimizer.param_groups[0]['lr']\n        print(f\"\
          Epoch [{epoch+1}/{epochs}] Loss: {avg_loss:.4f} | Val Acc: {val_acc:.2f}%\
          \ | LR: {current_lr:.2e}\")\n\n        if val_acc > best_val_acc:\n    \
          \        best_val_acc = val_acc\n            torch.save(model.state_dict(),\
          \ \"/app/best_model.pth\")\n\n    print(f\"\\n{'#'*60}\")\n    print(f\"\
          # PHASE 1 COMPLETED: Training Done!\")\n    print(f\"# Best Validation Accuracy:\
          \ {best_val_acc:.2f}%\")\n    print(f\"# Model saved to: /app/best_model.pth\"\
          )\n    print(f\"{'#'*60}\\n\")\n\n    # =====================================================\n\
          \    # PHASE 2: EVALUATION\n    # =====================================================\n\
          \    print(f\"\\n{'#'*60}\")\n    print(f\"# PHASE 2: MODEL EVALUATION\"\
          )\n    print(f\"{'#'*60}\\n\")\n\n    # Load best model for final evaluation\n\
          \    model_path = \"/app/best_model.pth\"\n    print(f\"Loading best model\
          \ from: {model_path}\\n\")\n\n    model.load_state_dict(torch.load(model_path,\
          \ map_location=device))\n    model.eval()\n\n    # Per-class evaluation\n\
          \    print(\"Computing per-class accuracy...\\n\")\n    class_correct =\
          \ [0] * len(class_names)\n    class_total = [0] * len(class_names)\n\n \
          \   with torch.no_grad():\n        for val_batch in val_loader:\n      \
          \      val_inputs = val_batch[\"image\"].to(device)\n            val_labels\
          \ = val_batch[\"label\"].to(device)\n            val_outputs = model(val_inputs)\n\
          \            _, predicted = torch.max(val_outputs, 1)\n\n            for\
          \ label, pred in zip(val_labels, predicted):\n                label_item\
          \ = label.item()\n                class_total[label_item] += 1\n       \
          \         if label_item == pred.item():\n                    class_correct[label_item]\
          \ += 1\n\n    print(\"Per-class accuracy:\")\n    for i, class_name in enumerate(class_names):\n\
          \        if class_total[i] > 0:\n            class_acc = 100 * class_correct[i]\
          \ / class_total[i]\n            print(f\"  {class_name:12s}: {class_acc:6.2f}%\"\
          )\n\n    print(f\"\\n{'#'*60}\")\n    print(f\"# PHASE 2 COMPLETED: Evaluation\
          \ Done!\")\n    print(f\"# Overall Validation Accuracy: {best_val_acc:.2f}%\"\
          )\n    print(f\"{'#'*60}\\n\")\n\n    # Log metrics to Kubeflow\n    metrics_output.log_metric(\"\
          validation_accuracy\", round(best_val_acc, 2))\n    metrics_output.log_metric(\"\
          epochs\", epochs)\n    metrics_output.log_metric(\"batch_size\", batch_size)\n\
          \n    print(f\"\\n{'='*60}\")\n    print(f\"Pipeline completed successfully!\"\
          )\n    print(f\"{'='*60}\\n\")\n\n"
        image: phuochovan/monai-training:v3
        resources:
          cpuLimit: 4.0
          memoryLimit: 4.294967296
          resourceCpuLimit: '4'
          resourceMemoryLimit: 4Gi
pipelineInfo:
  description: Train and evaluate medical image classification model
  name: monai-medical-image-classification
root:
  dag:
    tasks:
      train-and-evaluate-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train-and-evaluate-model
        inputs:
          parameters:
            batch_size:
              componentInputParameter: batch_size
            epochs:
              componentInputParameter: epochs
        taskInfo:
          name: train-and-evaluate-model
  inputDefinitions:
    parameters:
      batch_size:
        defaultValue: 32.0
        description: 'Training batch size (default: 32)'
        isOptional: true
        parameterType: NUMBER_INTEGER
      epochs:
        defaultValue: 3.0
        description: 'Number of training epochs (default: 3)'
        isOptional: true
        parameterType: NUMBER_INTEGER
schemaVersion: 2.1.0
sdkVersion: kfp-2.14.6
