# H∆∞·ªõng D·∫´n Ch·∫°y T·ª´ng B∆∞·ªõc - MONAI AI cho B·ªánh vi·ªán

## üéØ M·ª•c ti√™u

Ch·∫°y to√†n b·ªô quy tr√¨nh:
1. ‚úÖ T·∫£i pretrained model
2. ‚úÖ T·∫£i sample data (gi·∫£ l·∫≠p data b·ªánh vi·ªán)
3. ‚úÖ Test model tr√™n data m·ªõi
4. ‚úÖ Fine-tune (n·∫øu c·∫ßn)
5. ‚úÖ Deploy inference service

**Timeline**: 2-3 gi·ªù (bao g·ªìm download)

---

## B∆∞·ªõc 1: Setup M√¥i tr∆∞·ªùng (15 ph√∫t)

### 1.1 Clone Project

```bash
git clone <repo-url>
cd hospital-mlops
```

### 1.2 T·∫°o Virtual Environment

```bash
# T·∫°o venv
python -m venv venv

# Activate
# Linux/Mac:
source venv/bin/activate

# Windows:
venv\Scripts\activate
```

### 1.3 Install Dependencies

```bash
# Install core packages
pip install -r requirements.txt

# Install additional required packages
pip install huggingface_hub

# Install LungMask
pip install git+https://github.com/JoHof/lungmask

# Verify
python -c "import monai; print(f'MONAI {monai.__version__}')"
python -c "import lungmask; print('LungMask installed')"
```

**Expected output**:
```
MONAI 1.3.0
LungMask installed
```

**Note**: Package `huggingface_hub` c·∫ßn thi·∫øt ƒë·ªÉ download MONAI models t·ª´ Hugging Face

---

## B∆∞·ªõc 2: Download Pretrained Model (20 ph√∫t)

### 2.1 Download MONAI Whole Body CT

```bash
cd hospital-mlops/pretrained-models

# Download (~144 MB, ~10 gi√¢y v·ªõi internet t·ªët)
python -m monai.bundle download "wholeBody_ct_segmentation" --bundle_dir ./
```

**K·∫øt qu·∫£**:
```
pretrained-models/
‚îî‚îÄ‚îÄ wholeBody_ct_segmentation/
    ‚îú‚îÄ‚îÄ configs/
    ‚îÇ   ‚îú‚îÄ‚îÄ inference.json
    ‚îÇ   ‚îú‚îÄ‚îÄ metadata.json
    ‚îÇ   ‚îú‚îÄ‚îÄ train.json
    ‚îÇ   ‚îî‚îÄ‚îÄ evaluate.json
    ‚îú‚îÄ‚îÄ models/
    ‚îÇ   ‚îú‚îÄ‚îÄ model.pt          # 72 MB (high resolution)
    ‚îÇ   ‚îî‚îÄ‚îÄ model_lowres.pt   # 72 MB (low resolution)
    ‚îú‚îÄ‚îÄ docs/
    ‚îÇ   ‚îî‚îÄ‚îÄ README.md
    ‚îî‚îÄ‚îÄ LICENSE
```

**Total**: ~144 MB cho 2 model versions

### 2.2 Download LungMask (t·ª± ƒë·ªông khi ch·∫°y l·∫ßn ƒë·∫ßu)

LungMask weights t·ª± ƒë·ªông download khi ch·∫°y script test l·∫ßn ƒë·∫ßu ti√™n.

Kh√¥ng c·∫ßn download th·ªß c√¥ng - s·∫Ω t·ª± ƒë·ªông t·∫£i khi b·∫°n ch·∫°y `test_lungmask.py` ·ªü B∆∞·ªõc 4.

Weights (~30MB) s·∫Ω ƒë∆∞·ª£c l∆∞u v√†o `~/.cache/torch/hub/`

### 2.3 (Optional) Download COVID-19 Model

```bash
python -m monai.bundle download "covid19_lung_ct_segmentation" --bundle_dir ./
```

---

## B∆∞·ªõc 3: T·∫£i Sample Data - Gi·∫£ l·∫≠p Data B·ªánh vi·ªán (30 ph√∫t)

### 3.1 Download Medical Decathlon Dataset

S·ª≠ d·ª•ng **Medical Segmentation Decathlon** - dataset public cho CT lung:

**Option 1: D√πng MONAI API (Khuy·∫øn ngh·ªã)**

T·∫°o file `hospital-mlops/demo/download_lung_data.py`:

```python
#!/usr/bin/env python
"""Download Medical Decathlon Task06_Lung dataset"""
from monai.apps import DecathlonDataset
from pathlib import Path

# T·∫°o folder
data_dir = Path("./sample-data")
data_dir.mkdir(parents=True, exist_ok=True)

print("Downloading Medical Decathlon Task06_Lung...")
print("Size: ~2 GB, time: ~5-10 ph√∫t")

# Download Task06_Lung (63 CT scans)
dataset = DecathlonDataset(
    root_dir=str(data_dir),
    task="Task06_Lung",
    section="training",
    download=True,
    num_workers=4
)

print(f"\n‚úì Downloaded {len(dataset)} cases")
print(f"‚úì Location: {data_dir / 'Task06_Lung'}")
```

Ch·∫°y:
```bash
cd hospital-mlops/demo
python download_lung_data.py
```

**Option 2: Download tr·ª±c ti·∫øp (n·∫øu Option 1 l·ªói)**

```bash
cd hospital-mlops/demo
mkdir -p sample-data
cd sample-data

# Download Task06_Lung (~2 GB)
wget https://msd-for-monai.s3-us-west-2.amazonaws.com/Task06_Lung.tar
tar -xf Task06_Lung.tar
rm Task06_Lung.tar
```

**K·∫øt qu·∫£**:
```
demo/sample-data/
‚îî‚îÄ‚îÄ Task06_Lung/
    ‚îú‚îÄ‚îÄ imagesTr/        # 63 CT scans
    ‚îÇ   ‚îú‚îÄ‚îÄ lung_001.nii.gz
    ‚îÇ   ‚îú‚îÄ‚îÄ lung_003.nii.gz
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îú‚îÄ‚îÄ labelsTr/        # 63 ground truth masks
    ‚îÇ   ‚îú‚îÄ‚îÄ lung_001.nii.gz
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îî‚îÄ‚îÄ dataset.json
```

### 3.2 Verify Data Downloaded

**Linux/Mac:**
```bash
cd hospital-mlops/demo

# Ki·ªÉm tra s·ªë l∆∞·ª£ng CT scans
ls sample-data/Task06_Lung/imagesTr/*.nii.gz | wc -l
# Output: 63

ls sample-data/Task06_Lung/labelsTr/*.nii.gz | wc -l
# Output: 63
```

**Windows PowerShell:**
```powershell
cd hospital-mlops/demo

# Ki·ªÉm tra s·ªë l∆∞·ª£ng CT scans
(ls sample-data/Task06_Lung/imagesTr/*.nii.gz).Count
# Output: 63

(ls sample-data/Task06_Lung/labelsTr/*.nii.gz).Count
# Output: 63

# Ki·ªÉm tra file ƒë·∫ßu ti√™n
ls sample-data/Task06_Lung/imagesTr/lung_001.nii.gz
```

**Note**:
- Dataset c√≥ 63 CT scans (kh√¥ng ph·∫£i 64)
- C√≥ th·ªÉ th·∫•y t·ªïng files > 63 do c√≥ c√°c file metadata (._lung_*.nii.gz) t·ª´ Mac

**QUAN TR·ªåNG**:
- Medical Decathlon Task06_Lung ch·ªâ c√≥ **cancer labels**, kh√¥ng ph·∫£i lung segmentation labels
- Kh√¥ng th·ªÉ t√≠nh Dice score v·ªõi ground truth
- S·ª≠ d·ª•ng script `test_lungmask_simple.py` ƒë·ªÉ test (kh√¥ng c·∫ßn ground truth)

---

## B∆∞·ªõc 4: Test Pretrained Model (5-10 ph√∫t)

### 4.1 Test LungMask - Simple Version (Recommended)

Ch·∫°y script ƒë∆°n gi·∫£n kh√¥ng c·∫ßn ground truth:

```bash
cd hospital-mlops/demo
python test_lungmask_simple.py
```

**L·∫ßn ƒë·∫ßu ch·∫°y**:
- LungMask s·∫Ω t·ª± ƒë·ªông download weights (~30MB) v√†o `~/.cache/torch/hub/`
- M·∫•t ~1-2 ph√∫t/patient tr√™n CPU (80-100 gi√¢y)

**Script n√†y s·∫Ω**:
- Test LungMask tr√™n 5 cases ƒë·∫ßu ti√™n t·ª´ Medical Decathlon
- T√≠nh lung volume (total, left, right)
- T√≠nh inference time
- L∆∞u predictions v√†o `./sample-data/predictions/`
- L∆∞u k·∫øt qu·∫£ JSON v√†o `./test_results_simple.json`

**Chi ti·∫øt code**: Xem `hospital-mlops/demo/test_lungmask_simple.py`

**Expected Output**:

```
============================================================
LungMask Testing Script
Testing pretrained model on Medical Decathlon data
============================================================

Found 5 patients to test

Initializing LungMask model (R231)...
[OK] Model loaded

============================================================
Testing: lung_001.nii.gz
============================================================
Loading CT scan...
Running LungMask inference...
  Inference time: 79.10 seconds
  Lung volume: 3851.3 ml
  Left lung: 2106.9 ml
  Right lung: 1744.4 ml
  Saved to: ./sample-data/predictions/lung_001.nii_pred.nii.gz

============================================================
Testing: lung_003.nii.gz
============================================================
...

============================================================
SUMMARY
============================================================

Tested 5 patients:

Patient              Time (s)     Total (ml)   Left (ml)    Right (ml)
----------------------------------------------------------------------
lung_001.nii         79.10        3851.3       2106.9       1744.4
lung_003.nii         91.41        6494.8       3480.5       3014.4
lung_004.nii         100.25       6063.8       3247.5       2816.3
lung_005.nii         86.75        3915.6       2084.1       1831.6
lung_006.nii         146.09       5515.3       2690.4       2824.9
----------------------------------------------------------------------
AVERAGE              100.72       5168.2       2721.9       2446.3

[OK] Average Inference Time: 100.72 seconds
[OK] Average Total Lung Volume: 5168.2 ml
[OK] Predictions saved to: ./sample-data/predictions/

============================================================
CLINICAL INTERPRETATION
============================================================

[OK] Model successfully segmented lungs for 5/5 patients
[OK] Average lung volume: 5168 ml (normal range: 4000-6000 ml)
[OK] Left/Right ratio: 1.11 (normal: ~0.9-1.1)
[OK] Lung volumes are within normal range

Next steps:
  1. Visualize results: python visualize_results.py
  2. Deploy service: cd ../deployment && python serve.py
============================================================
```

### 4.2 Test MONAI Whole Body CT

T·∫°o file `test_monai_wholebody.py`:

```python
#!/usr/bin/env python
"""
Test MONAI Whole Body CT model
"""

import torch
from monai.bundle import ConfigParser
from pathlib import Path
import SimpleITK as sitk
import numpy as np
import time

def test_wholebody_model():
    """Test MONAI Whole Body CT"""

    # Load model config
    config_path = Path("../pretrained-models/wholeBody_ct_segmentation/configs/inference.json")

    if not config_path.exists():
        print(f"‚úó Model not found: {config_path}")
        print("Please download first: python -m monai.bundle download wholeBody_ct_segmentation")
        return

    print("Loading MONAI Whole Body CT model...")
    parser = ConfigParser()
    parser.read_config(str(config_path))

    # Load model
    model = parser.get_parsed_content("network_def")
    model_path = Path("../pretrained-models/wholeBody_ct_segmentation/models/model.pt")
    model.load_state_dict(torch.load(str(model_path)))
    model.eval()

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    print(f"‚úì Model loaded on {device}")

    # Test on first patient
    image_path = Path("test-cases/patient_001_image.nii.gz")

    if not image_path.exists():
        print(f"‚úó Test data not found: {image_path}")
        return

    print(f"\nTesting on: {image_path.name}")

    # Load and preprocess
    ct_scan = sitk.ReadImage(str(image_path))
    ct_array = sitk.GetArrayFromImage(ct_scan)

    # Convert to tensor
    ct_tensor = torch.from_numpy(ct_array).float().unsqueeze(0).unsqueeze(0)
    ct_tensor = ct_tensor.to(device)

    print("Running inference...")
    start = time.time()

    with torch.no_grad():
        output = model(ct_tensor)

    inference_time = time.time() - start

    print(f"\n‚úì Inference complete!")
    print(f"  Output shape: {output.shape}")
    print(f"  Channels (organs): {output.shape[1]}")
    print(f"  Inference time: {inference_time:.2f} seconds")

    # Extract lung channels (example: channels 1-2)
    lung_mask = output[0, 1:3, ...].cpu().numpy()  # Channels 1, 2 = left/right lung

    print(f"\n‚úì Extracted lung segmentation from 104 organs")
    print(f"  Can also extract: heart, liver, trachea, vessels, etc.")

if __name__ == "__main__":
    test_wholebody_model()
```

Ch·∫°y:
```bash
python test_monai_wholebody.py
```

---

## B∆∞·ªõc 5: Visualize Results (15 ph√∫t)

Ch·∫°y script c√≥ s·∫µn:

```bash
cd hospital-mlops/demo
python visualize_results.py
```

**Script n√†y s·∫Ω**:
- T·∫°o visualizations cho t·∫•t c·∫£ test cases
- So s√°nh Ground Truth vs Prediction
- T·∫°o difference maps (error analysis)
- T·∫°o summary plot v·ªõi Dice scores
- L∆∞u t·∫•t c·∫£ v√†o folder `visualizations/`

**Chi ti·∫øt code**: Xem `hospital-mlops/demo/visualize_results.py`

**Output**:
```bash
visualizations/
‚îú‚îÄ‚îÄ lung_001_comparison.png
‚îú‚îÄ‚îÄ lung_002_comparison.png
‚îú‚îÄ‚îÄ lung_003_comparison.png
‚îú‚îÄ‚îÄ lung_004_comparison.png
‚îú‚îÄ‚îÄ lung_005_comparison.png
‚îî‚îÄ‚îÄ summary_dice_scores.png
```

M·ªói file PNG ch·ª©a:
- **Row 1**: Original CT | Ground Truth | Prediction
- **Row 2**: GT Mask | Pred Mask | Difference Map

---

## B∆∞·ªõc 6: (Optional) Fine-tune Model (2-3 gi·ªù)

N·∫øu mu·ªën fine-tune v·ªõi data b·ªánh vi·ªán:

```bash
# Chu·∫©n b·ªã training data (50 cases)
mkdir -p ../fine-tuning/hospital-data/train
mkdir -p ../fine-tuning/hospital-data/val

# Copy 40 cases cho training
# Copy 10 cases cho validation

# Run fine-tuning
cd ../fine-tuning
python train.py \
  --pretrained ../pretrained-models/wholeBody_ct_segmentation/models/model.pt \
  --data hospital-data/ \
  --epochs 20 \
  --batch-size 2 \
  --lr 5e-5
```

---

## B∆∞·ªõc 7: Deploy Inference Service (30 ph√∫t)

### 7.1 Install FastAPI Dependencies

```bash
pip install fastapi uvicorn python-multipart
```

### 7.2 Start Service

```bash
cd hospital-mlops/deployment
python serve.py
```

**Chi ti·∫øt code**: Xem `hospital-mlops/deployment/serve.py` v√† `hospital-mlops/deployment/README.md`

Server s·∫Ω ch·∫°y t·∫°i: `http://localhost:8000`

### 7.3 Test API

**Health Check:**
```bash
curl http://localhost:8000/health
```

**Response:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "model_name": "R231"
}
```

**Segment Lung:**
```bash
curl -X POST "http://localhost:8000/segment" \
  -F "file=@./sample-data/Task06_Lung/imagesTr/lung_001.nii.gz"
```

**Response:**
```json
{
  "status": "success",
  "lung_volume_ml": 4523.8,
  "inference_time_seconds": 5.2,
  "patient_id": "lung_001",
  "model_used": "R231"
}
```

### 7.4 Interactive API Docs

M·ªü browser: `http://localhost:8000/docs`

FastAPI t·ª± ƒë·ªông t·∫°o Swagger UI ƒë·ªÉ test API interactively.

---

## ‚úÖ T·ªïng k·∫øt

Sau khi ho√†n th√†nh t·∫•t c·∫£ b∆∞·ªõc:

‚úÖ **ƒê√£ test**: 5 CT scans t·ª´ Medical Decathlon
‚úÖ **Lung Volume**: 5168 ml average (trong kho·∫£ng b√¨nh th∆∞·ªùng 4000-6000 ml)
‚úÖ **Left/Right Ratio**: 1.11 (b√¨nh th∆∞·ªùng)
‚úÖ **Speed**: ~100 gi√¢y/b·ªánh nh√¢n (tr√™n CPU)
‚úÖ **Success Rate**: 5/5 patients (100%)

### K·∫øt qu·∫£ Th·ª±c t·∫ø:

```
Model: LungMask R231
Total patients tested: 5/5 successful

Average Metrics:
- Total lung volume: 5168.2 ml ‚úì
- Left lung: 2721.9 ml
- Right lung: 2446.3 ml
- L/R ratio: 1.11 ‚úì
- Inference time: 100.72 seconds (CPU)
```

### L∆∞u √Ω quan tr·ªçng:

‚ö†Ô∏è **Medical Decathlon Task06_Lung** ch·ªâ c√≥ **cancer labels**, kh√¥ng ph·∫£i lung segmentation labels.
- Kh√¥ng th·ªÉ t√≠nh Dice score v·ªõi ground truth
- Model v·∫´n ho·∫°t ƒë·ªông t·ªët, verified qua lung volumes
- Lung volumes v√† L/R ratio ƒë·ªÅu trong kho·∫£ng b√¨nh th∆∞·ªùng

### Next Steps:

1. ‚úÖ **Model ƒë√£ s·∫µn s√†ng s·ª≠ d·ª•ng** - Lung volumes ch√≠nh x√°c
2. ‚è≠ Visualize predictions: `python visualize_results.py`
3. ‚è≠ Deploy API service: `cd ../deployment && python serve.py`
4. ‚è≠ (Optional) Test v·ªõi GPU ƒë·ªÉ tƒÉng t·ªëc (~5 gi√¢y thay v√¨ 100 gi√¢y)

---

**Timeline Summary**:
- Setup: 15 ph√∫t
- Download models: 10 ph√∫t (144 MB)
- Download data: ƒê√£ c√≥ s·∫µn (~2 GB)
- Test models: 5-10 ph√∫t (5 patients)
- Visualize: 15 ph√∫t
- Deploy: 30 ph√∫t
**= Total: ~1.5 gi·ªù**

**Model ƒë√£ s·∫µn s√†ng s·ª≠ d·ª•ng!**
